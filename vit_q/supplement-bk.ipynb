{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary Analysis\n",
    "> BF15 Numerical Accuracy\n",
    "\n",
    "> Date.11/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T00:09:12.811235Z",
     "iopub.status.busy": "2025-11-05T00:09:12.810671Z",
     "iopub.status.idle": "2025-11-05T00:09:12.823386Z",
     "shell.execute_reply": "2025-11-05T00:09:12.822368Z"
    }
   },
   "outputs": [],
   "source": [
    "# Env info\n",
    "import sys\n",
    "\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"Python path:\", sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T00:09:12.891692Z",
     "iopub.status.busy": "2025-11-05T00:09:12.891260Z",
     "iopub.status.idle": "2025-11-05T00:09:16.141994Z",
     "shell.execute_reply": "2025-11-05T00:09:16.141017Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "# from bf15_linear import replace_linear_with_bf15\n",
    "# from bfspmat import replace_linear_with_bf15 as replace_linear_with_bf15_full\n",
    "from vit import ImageNetValDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T00:09:16.146659Z",
     "iopub.status.busy": "2025-11-05T00:09:16.146002Z",
     "iopub.status.idle": "2025-11-05T00:09:16.732631Z",
     "shell.execute_reply": "2025-11-05T00:09:16.731898Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# bf15_linear.py  ——  BF15 仿真 Linear（frexp 截尾法，GPU 向量化）\n",
    "ORIG_MATMUL = torch.matmul\n",
    "\n",
    "# 原子核规格：1x64 与 64x8（你可按需改）\n",
    "_TILE_M, _TILE_K, _TILE_N = 1, 64, 8\n",
    "\n",
    "# 全局计数器\n",
    "_HW = {\"tiles_total\": 0, \"tiles_matmul\": 0, \"tiles_conv\": 0}\n",
    "\n",
    "def reset_hw_counter():\n",
    "    _HW[\"tiles_total\"] = 0\n",
    "    _HW[\"tiles_matmul\"] = 0\n",
    "    _HW[\"tiles_conv\"] = 0\n",
    "\n",
    "def _ceil_div(a, b):\n",
    "    return (a + b - 1) // b\n",
    "\n",
    "def count_matmul_tiles(M, K, N, kind=\"matmul\"):\n",
    "    tiles = _ceil_div(M, _TILE_M) * _ceil_div(K, _TILE_K) * _ceil_div(N, _TILE_N)\n",
    "    _HW[\"tiles_total\"] += tiles\n",
    "    if kind == \"matmul\":\n",
    "        _HW[\"tiles_matmul\"] += tiles\n",
    "    elif kind == \"conv\":\n",
    "        _HW[\"tiles_conv\"] += tiles\n",
    "    return tiles\n",
    "\n",
    "def report_hw_counter(freq_hz=200_000_000):\n",
    "    # 1 原子核 / 周期，理想串行模型\n",
    "    cycles = _HW[\"tiles_total\"]\n",
    "    seconds = cycles / float(freq_hz)\n",
    "    ms = seconds * 1e3\n",
    "    us = seconds * 1e6\n",
    "    print(f\"[BF15-HW] tiles_total={_HW['tiles_total']}, matmul={_HW['tiles_matmul']}, conv={_HW['tiles_conv']}\")\n",
    "    if ms >= 1.0:\n",
    "        print(f\"[BF15-HW] 估计总时延: {ms:.2f} ms @ 200 MHz\")\n",
    "    else:\n",
    "        print(f\"[BF15-HW] 估计总时延: {us:.2f} µs @ 200 MHz\")\n",
    "\n",
    "# ---------------------------\n",
    "# 1) 将张量数值“仿真成 BF15”\n",
    "#    （在 FP32 域用 frexp 拆分，再清掉尾数最低1位）\n",
    "# ---------------------------\n",
    "@torch.no_grad()\n",
    "def to_bf15_real_fp32(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    输入: 任意 dtype/cuda\n",
    "    输出: FP32 张量，其数值等价于把 x 转成 BF16 后再清掉最后1位尾数（BF15）\n",
    "    做法：\n",
    "      x = sign * mant * 2**exp, mant∈[0.5,1)\n",
    "      规范化到 [1,2): mant1 = mant*2, exp1 = exp-1\n",
    "      量化到 7bit 且清掉最低1位： m_q = floor(mant1*128) -> m_q = (m_q // 2) * 2\n",
    "      最终值： sign * (m_q/128) * 2**exp1\n",
    "    \"\"\"\n",
    "    x32 = x.to(torch.float32)\n",
    "    sign = torch.sign(x32)\n",
    "    ax   = torch.abs(x32)\n",
    "\n",
    "    mant, exp = torch.frexp(ax)    # ax = mant * 2**exp, mant ∈ [0.5,1)\n",
    "    mant1 = mant * 2.0\n",
    "    exp1  = exp  - 1.0\n",
    "\n",
    "    m_q = torch.floor(mant1 * 128.0)            # 2**7\n",
    "    m_q = torch.floor(m_q / 2.0) * 2.0          # 清掉最低1位 (BF15)\n",
    "\n",
    "    # 零值保护（frexp(0)返回mant=0, exp=0，这里直接返回0）\n",
    "    zero = (ax == 0)\n",
    "    real = sign * (m_q / 128.0) * torch.pow(torch.tensor(2.0, device=x32.device), exp1)\n",
    "    real = torch.where(zero, torch.zeros_like(real), real)\n",
    "    return real  # FP32\n",
    "\n",
    "# ---------------------------\n",
    "# 2) BF15 仿真 matmul（全向量化）\n",
    "# ---------------------------\n",
    "@torch.no_grad()\n",
    "def bf15_left_matmul(A: torch.Tensor, B: torch.Tensor, count_hw: bool = True) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    只把左矩阵 A 仿真为 BF15，再用 FP32 matmul。\n",
    "    同时模拟硬件 tile 划分与总时延估计。\n",
    "    \"\"\"\n",
    "\n",
    "    # 左矩阵：BF15 实值（FP32）\n",
    "    A_bf15 = to_bf15_real_fp32(A)\n",
    "    # 右矩阵：BF16 转 FP32\n",
    "    B_real = B.to(torch.float32)\n",
    "    \n",
    "    if A.dim() == 2 and B.dim() == 2:\n",
    "        M, K = A.shape\n",
    "        K2, N = B.shape\n",
    "        if K == K2:\n",
    "            count_matmul_tiles(M, K, N, kind=\"matmul\")\n",
    "\n",
    "    # ---- 实际 matmul ----\n",
    "    out_fp32 = ORIG_MATMUL(A_bf15, B_real)\n",
    "    return out_fp32.to(torch.bfloat16)\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 3) 可替换 nn.Linear 的模块\n",
    "# ---------------------------\n",
    "class BF15IntLinear(nn.Module):\n",
    "    \"\"\"\n",
    "    用 BF15 仿真 matmul 替代 nn.Linear（推理用）\n",
    "    - 内部把输入与权重都做 BF15 截尾仿真，再执行 matmul\n",
    "    - 输出 dtype 为 BF16，方便与 ViT 其它算子衔接\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True):\n",
    "        super().__init__()\n",
    "        self.in_features  = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.empty(out_features, in_features), requires_grad=False)\n",
    "        self.bias   = nn.Parameter(torch.zeros(out_features), requires_grad=False) if bias else None\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in = self.in_features\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x2d = x.reshape(-1, x.shape[-1])              # [..., in] -> [M, K]\n",
    "        # 左：输入 x 仿真 BF15；右：weight^T 保持 BF16 的真实值\n",
    "        y2d = bf15_left_matmul(x2d, self.weight.t())\n",
    "        if self.bias is not None:\n",
    "            y2d = (y2d.to(torch.float32) + self.bias.to(torch.float32)).to(torch.bfloat16)\n",
    "        return y2d.reshape(*x.shape[:-1], self.out_features)\n",
    "\n",
    "# ---------------------------\n",
    "# 4) 递归替换工具\n",
    "# ---------------------------\n",
    "def replace_linear_with_bf15(model: nn.Module):\n",
    "    for name, module in list(model.named_children()):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            new_layer = BF15IntLinear(module.in_features, module.out_features, module.bias is not None)\n",
    "            # 拷贝权重到 FP32（内部再仿真成 BF15 实值用于计算）\n",
    "            new_layer.weight.data.copy_(module.weight.data.float())\n",
    "            if module.bias is not None:\n",
    "                new_layer.bias.data.copy_(module.bias.data.float())\n",
    "            setattr(model, name, new_layer)\n",
    "        else:\n",
    "            replace_linear_with_bf15(module)\n",
    "\n",
    "# ---------------------------\n",
    "# 5) 自测\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    torch.manual_seed(0)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    A = torch.randn(8, 16, dtype=torch.bfloat16, device=device)\n",
    "    B = torch.randn(16, 32, dtype=torch.bfloat16, device=device)\n",
    "\n",
    "    y_sim = bf15_left_matmul(A, B)\n",
    "    y_ref = torch.matmul(A.to(torch.float32), B.to(torch.float32)).to(torch.bfloat16)\n",
    "\n",
    "    print(\"max abs diff:\", (y_sim - y_ref).abs().max().item())\n",
    "\n",
    "    layer = BF15IntLinear(16, 32).to(device)\n",
    "    x = torch.randn(4, 16, dtype=torch.bfloat16, device=device)\n",
    "    y = layer(x)\n",
    "    print(\"Output:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T00:09:16.736678Z",
     "iopub.status.busy": "2025-11-05T00:09:16.736415Z",
     "iopub.status.idle": "2025-11-05T00:09:16.815865Z",
     "shell.execute_reply": "2025-11-05T00:09:16.815004Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# --------- 和原实现保持一致的拆分函数（支持 left=BF15 截尾） ----------\n",
    "@torch.no_grad()\n",
    "def split_to_bf_parts(x: torch.Tensor, left: bool):\n",
    "    \"\"\"\n",
    "    输出:\n",
    "      m_signed: int32, 代表带符号的“规格化尾数 * 128”（[±128..±255]）\n",
    "      e_unbias: int32, 无偏指数（2 的指数），满足:  real ~= (m_signed / 128) * 2**e_unbias\n",
    "    left=True 时对 m_signed 清掉最低 1 bit → 对应 BF15（左矩阵用）\n",
    "    \"\"\"\n",
    "    x32  = x.to(torch.float32)\n",
    "    zero = (x32 == 0)\n",
    "    sgn  = torch.sign(x32)\n",
    "    ax   = torch.abs(x32)\n",
    "\n",
    "    mant, exp = torch.frexp(ax)          # ax = mant * 2**exp, mant∈[0.5,1)\n",
    "    mant1 = mant * 2.0                   # → [1,2)\n",
    "    e_unb = exp - 1.0\n",
    "\n",
    "    m_scaled = torch.floor(mant1 * 128.0).to(torch.int32)   # [128..255]\n",
    "    if left:\n",
    "        m_scaled = (m_scaled >> 1) << 1                     # 清掉 LSB（BF15）\n",
    "\n",
    "    m_signed = torch.where(sgn < 0, -m_scaled, m_scaled).to(torch.int32)\n",
    "    m_signed = torch.where(zero, torch.zeros_like(m_signed), m_signed)\n",
    "    e_unb    = torch.where(zero, torch.zeros_like(e_unb),    e_unb).to(torch.int32)\n",
    "    return m_signed, e_unb\n",
    "\n",
    "\n",
    "# ------------------ 优化版：全 GPU 并行的块内整数仿真 + 块间浮点累加 ------------------\n",
    "@torch.no_grad()\n",
    "def bf15_left_exp_int_matmul(A: torch.Tensor, B: torch.Tensor, tile_k: int = 64) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    A: [M,K]（左矩阵量化为 BF15：清尾数 LSB）\n",
    "    B: [K,N]（右矩阵保持 BF16 精度：7-bit 尾数，不清 LSB）\n",
    "    过程：\n",
    "      - 块内（tile_k）：整数域仿真（指数对齐 + 尾数右移“趋零截断” + 沿K求和）\n",
    "      - 块间（所有 tile）：一次性浮点累加（batch reduce），保持与旧版一致的误差\n",
    "    返回：FP32（可按需 .to(torch.bfloat16)）\n",
    "    \"\"\"\n",
    "    assert A.dim() == 2 and B.dim() == 2\n",
    "    M, K = A.shape\n",
    "    K2, N = B.shape\n",
    "    assert K == K2, \"Inner dimension mismatch\"\n",
    "\n",
    "    device = A.device\n",
    "    # 1) 拆分（保持与旧逻辑一致）\n",
    "    Am, Ae = split_to_bf_parts(A, left=True)    # int32\n",
    "    Bm, Be = split_to_bf_parts(B, left=False)   # int32\n",
    "\n",
    "    # 2) 将 K 维分块并“批处理”（把所有 tile 堆到 batch 维，GPU 并行处理）\n",
    "    T = (K + tile_k - 1) // tile_k                        # tile 个数\n",
    "    pad_k = T * tile_k - K                                # 末块 padding 的长度\n",
    "\n",
    "    if pad_k > 0:\n",
    "        # 左矩阵沿 K 维 pad 在末尾（0 填充不影响数值）\n",
    "        Am = F.pad(Am, (0, pad_k), value=0)\n",
    "        Ae = F.pad(Ae, (0, pad_k), value=0)\n",
    "        # 右矩阵沿 K 维 pad 在开头或末尾均可（与上面保持一致的方向）\n",
    "        Bm = F.pad(Bm, (0, 0, 0, pad_k), value=0)  # pad on dim=0 (K)\n",
    "        Be = F.pad(Be, (0, 0, 0, pad_k), value=0)\n",
    "\n",
    "    # 现在 K_pad = T * tile_k，可 reshape 为 [T, *]\n",
    "    K_pad = T * tile_k\n",
    "    Am_t = Am.reshape(M, T, tile_k).transpose(0, 1).contiguous()      # [T, M, tile_k]\n",
    "    Ae_t = Ae.reshape(M, T, tile_k).transpose(0, 1).contiguous()      # [T, M, tile_k]\n",
    "    Bm_t = Bm.reshape(T, tile_k, N).contiguous()                       # [T, tile_k, N]\n",
    "    Be_t = Be.reshape(T, tile_k, N).contiguous()                       # [T, tile_k, N]\n",
    "\n",
    "    # 3) 计算每个 tile 的逐项乘积与指数和 （全部张量化，GPU 一次性并行）\n",
    "    # prod: [T, M, tile_k, N]   （int32）\n",
    "    prod  = Am_t.unsqueeze(-1) * Bm_t.unsqueeze(1)                     # (T,M,t,N)\n",
    "    e_sum = Ae_t.unsqueeze(-1) + Be_t.unsqueeze(1)                     # (T,M,t,N)\n",
    "\n",
    "    # 4) 块内指数对齐：E_ref_tile = max_k(e_sum)，右移“趋零截断”\n",
    "    E_ref = e_sum.max(dim=2, keepdim=True).values                      # (T,M,1,N)\n",
    "    shift = (E_ref - e_sum).clamp_min_(0)                              # (T,M,t,N), int32\n",
    "\n",
    "    # —— 用整数位移模拟 trunc toward 0:   aligned = trunc(prod / 2**shift)\n",
    "    #     算法：abs() 右移，最后按符号恢复\n",
    "    abs_prod    = prod.abs()\n",
    "    aligned_mag = abs_prod >> shift                                    # (T,M,t,N), int32\n",
    "    aligned     = torch.where(prod >= 0, aligned_mag, -aligned_mag)    # (T,M,t,N), int32\n",
    "\n",
    "    # 5) 沿 k（tile_k）求和得到每个 tile 的 S_tile、E_tile\n",
    "    S_tile = aligned.sum(dim=2, dtype=torch.int32)                     # (T,M,N), int32\n",
    "    E_tile = E_ref.squeeze(2).to(torch.int32)                          # (T,M,N), int32\n",
    "\n",
    "    # 6) 块间：浮点域一次性累加（与旧版语义一致）\n",
    "    #    两个 7-bit mantissa 相乘 → 总指数需减 14（2**14）\n",
    "    #    使用 torch.ldexp(mantissa, exponent) 更稳定：mantissa * 2**exponent\n",
    "    tile_fp32 = torch.ldexp(S_tile.to(torch.float32), (E_tile - 14))   # (T,M,N), float32\n",
    "    Y_fp32    = tile_fp32.sum(dim=0)                                   # (M,N),  float32\n",
    "\n",
    "    del Am, Ae, Bm, Be, e_sum, prod, aligned_mag, aligned, S_tile, E_tile, tile_fp32, abs_prod, shift, E_ref, Am_t, Ae_t, Bm_t, Be_t\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return Y_fp32  # .to(torch.bfloat16) 也可以\n",
    "\n",
    "# ====================== 额外集成：BF15 线性层 & ViT 一键替换 ======================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "@torch.no_grad()\n",
    "def to_bf15_real_fp32(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    将张量数值“仿真”为 BF15 的实值（返回 FP32）：\n",
    "      1) frexp 拆分 x = sign * mant * 2**exp, mant∈[0.5,1)\n",
    "      2) 映射到 [1,2): mant1=mant*2, exp1=exp-1\n",
    "      3) 量化到 7bit，再把最低 1 位清零（BF15）\n",
    "      4) 还原：sign * (m_q/128) * 2**exp1\n",
    "    说明：仅对“左操作数”做 BF15 截尾时，用这个输出作为 matmul 的输入更方便。\n",
    "    \"\"\"\n",
    "    x32  = x.to(torch.float32)\n",
    "    zero = (x32 == 0)\n",
    "    sgn  = torch.sign(x32)\n",
    "    ax   = torch.abs(x32)\n",
    "\n",
    "    mant, exp = torch.frexp(ax)      # mant∈[0.5,1)\n",
    "    mant1 = mant * 2.0               # [1,2)\n",
    "    exp1  = exp  - 1.0\n",
    "\n",
    "    m_q = torch.floor(mant1 * 128.0) # 7bit\n",
    "    m_q = torch.floor(m_q / 2.0) * 2.0   # 清掉 LSB → BF15\n",
    "\n",
    "    real = sgn * (m_q / 128.0) * torch.pow(torch.tensor(2.0, device=x32.device), exp1)\n",
    "    real = torch.where(zero, torch.zeros_like(real), real)\n",
    "    return real  # FP32\n",
    "\n",
    "\n",
    "class BF15IntLinear(nn.Module):\n",
    "    \"\"\"\n",
    "    用你的 bf15_left_exp_int_matmul 做核心 GEMM 的 Linear：\n",
    "      - 左输入仿真为 BF15（指数/尾数按你的实现来）\n",
    "      - 权重保持 BF16 实值路径（内部算法会拆分指数/尾数并对齐）\n",
    "      - 输出默认转回 BF16，方便接到 ViT 其它算子\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True):\n",
    "        super().__init__()\n",
    "        self.in_features  = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.empty(out_features, in_features), requires_grad=False)\n",
    "        self.bias   = nn.Parameter(torch.zeros(out_features), requires_grad=False) if bias else None\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            bound = 1 / math.sqrt(self.in_features)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # [*, in] → [M, K]\n",
    "        x2d = x.reshape(-1, x.shape[-1])\n",
    "        # 用你的 BF15 左乘仿真 matmul\n",
    "        y2d = bf15_left_exp_int_matmul(x2d, self.weight.t())\n",
    "        if self.bias is not None:\n",
    "            y2d = (y2d.to(torch.float32) + self.bias.to(torch.float32)).to(torch.bfloat16)\n",
    "        # [M, out] → [*, out]\n",
    "        return y2d.reshape(*x.shape[:-1], self.out_features)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def replace_linear_with_bf15(model: nn.Module):\n",
    "    \"\"\"\n",
    "    递归把模型里所有 nn.Linear 换成 BF15IntLinear，并拷贝参数。\n",
    "    用法：replace_linear_with_bf15(model)\n",
    "    \"\"\"\n",
    "    for name, module in list(model.named_children()):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            new_layer = BF15IntLinear(module.in_features, module.out_features, module.bias is not None)\n",
    "            new_layer.weight.data.copy_(module.weight.data.float())\n",
    "            if module.bias is not None:\n",
    "                new_layer.bias.data.copy_(module.bias.data.float())\n",
    "            setattr(model, name, new_layer)\n",
    "        else:\n",
    "            replace_linear_with_bf15(module)\n",
    "\n",
    "\n",
    "# ===================== Demo =======================\n",
    "if __name__ == \"__main__\":\n",
    "    torch.manual_seed(0)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    A = torch.randn(128, 256, dtype=torch.bfloat16, device=device)\n",
    "    B = torch.randn(256, 128, dtype=torch.bfloat16, device=device)\n",
    "\n",
    "    y_sim = bf15_left_exp_int_matmul(A, B, tile_k=64)\n",
    "    y_ref = torch.matmul(A.to(torch.float32), B.to(torch.float32))\n",
    "\n",
    "    diff = (y_sim - y_ref).abs()\n",
    "    print(\"max abs diff:\", float(diff.max()))\n",
    "    print(\"mean abs diff:\", float(diff.mean()))\n",
    "    print(\"Output:\", y_sim.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Error Budget Analysis\n",
    "- Max ULP (Units in the Last Place): The largest difference between the simulated BF15 and FP32 results.\n",
    "- Mean ULP: The average difference across all layers.\n",
    "- Histogram of ULPs: To visualize the distribution of errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T00:09:16.819571Z",
     "iopub.status.busy": "2025-11-05T00:09:16.819289Z",
     "iopub.status.idle": "2025-11-05T00:09:17.317448Z",
     "shell.execute_reply": "2025-11-05T00:09:17.316710Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 1. Error Budget Analysis\n",
    "# ==========================================\n",
    "def compute_error_budget(A, B, tile_k=64):\n",
    "    \"\"\"\n",
    "    Compute the error budget for BF15 truncation and post-alignment.\n",
    "    \"\"\"\n",
    "    # FP32 reference\n",
    "    y_ref = torch.matmul(A.to(torch.float32), B.to(torch.float32))\n",
    "\n",
    "    # BF15 with LSB truncation only\n",
    "    y_bf15_lsb = bf15_left_matmul(A, B)\n",
    "\n",
    "    # BF15 with LSB truncation + post-alignment\n",
    "    y_bf15_full = bf15_left_exp_int_matmul(A, B, tile_k=tile_k)\n",
    "\n",
    "    # Compute ULP differences\n",
    "    ulp_lsb = (y_bf15_lsb - y_ref).abs()\n",
    "    ulp_full = (y_bf15_full - y_ref).abs()\n",
    "\n",
    "    return ulp_lsb, ulp_full, y_ref, y_bf15_lsb, y_bf15_full\n",
    "\n",
    "# Generate random input tensors\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "A = torch.randn(128, 256, dtype=torch.bfloat16, device=device)\n",
    "B = torch.randn(256, 128, dtype=torch.bfloat16, device=device)\n",
    "\n",
    "# Compute error budget\n",
    "ulp_lsb, ulp_full, y_ref, y_bf15_lsb, y_bf15_full = compute_error_budget(A, B)\n",
    "\n",
    "# Plot histogram of ULPs\n",
    "density = False # Normalize the histogram\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.hist(ulp_lsb.cpu().numpy().flatten(), bins=50, alpha=0.5, label=\"LSB Truncation Only\", density=density)\n",
    "plt.hist(ulp_full.cpu().numpy().flatten(), bins=50, alpha=0.5, label=\"LSB + Post-Alignment\", density=density)\n",
    "plt.xlabel(\"ULP Error\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.legend()\n",
    "plt.title(\"Error Budget: ULP Distribution (Normalized)\")\n",
    "plt.savefig(\"error_budget_ulps_normalized.svg\", format=\"svg\")\n",
    "plt.show()\n",
    "\n",
    "# Print max and mean ULPs\n",
    "print(f\"Max ULP (LSB Only): {ulp_lsb.max().item()}\")\n",
    "print(f\"Mean ULP (LSB Only): {ulp_lsb.mean().item()}\")\n",
    "print(f\"Max ULP (LSB + Post-Alignment): {ulp_full.max().item()}\")\n",
    "print(f\"Mean ULP (LSB + Post-Alignment): {ulp_full.mean().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Ablation Study\n",
    "- Compare the outputs of the following configurations:\\\n",
    "FP32 baseline: Full precision.\\\n",
    "BF15 with LSB truncation only: Using `bf15_linear.py`.\\\n",
    "BF15 with LSB truncation + post-alignment: Using `bfspmat.py`.\n",
    "- Measure the accuracy (Top-1, Top-5) and inference time for each configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`wget https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz`\n",
    "\n",
    "`tar -xvzf imagenette2-320.tgz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T00:09:17.321508Z",
     "iopub.status.busy": "2025-11-05T00:09:17.321038Z",
     "iopub.status.idle": "2025-11-05T00:09:17.325889Z",
     "shell.execute_reply": "2025-11-05T00:09:17.325223Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 2. Ablation Study\n",
    "# ==========================================\n",
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "from bf15_linear import replace_linear_with_bf15\n",
    "from bfspmat import replace_linear_with_bf15 as replace_linear_with_bf15_full\n",
    "from vit import ImageNetValDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# Load ViT model\n",
    "weights = ViT_B_16_Weights.IMAGENET1K_V1\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_fp32 = vit_b_16(weights=weights).eval().to(device)\n",
    "\n",
    "# Clone models for BF15 configurations\n",
    "model_bf15_lsb = vit_b_16(weights=weights).eval()\n",
    "model_bf15_full = vit_b_16(weights=weights).eval()\n",
    "\n",
    "# Replace Linear layers\n",
    "replace_linear_with_bf15(model_bf15_lsb)  # LSB truncation only\n",
    "model_bf15_lsb.to(device)  # Ensure the model is on the correct device\n",
    "\n",
    "replace_linear_with_bf15_full(model_bf15_full)  # LSB + post-alignment\n",
    "model_bf15_full.to(device)  # Ensure the model is on the correct device\n",
    "\n",
    "# Load ImageNet validation dataset\n",
    "imagenet_root = \"./imagenette2-320/val\"  # Path to the validation dataset\n",
    "\n",
    "# Generate wnid_map directly from the folder structure\n",
    "def generate_wnid_map(root_dir):\n",
    "    classes = sorted(os.listdir(root_dir))\n",
    "    wnid_map = {cls: idx for idx, cls in enumerate(classes)}\n",
    "    return wnid_map\n",
    "\n",
    "wnid_map = generate_wnid_map(imagenet_root)\n",
    "\n",
    "# Preprocessing and dataset\n",
    "preprocess = weights.transforms()\n",
    "dataset = ImageNetValDataset(imagenet_root, wnid_map, preprocess)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Evaluate models\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    total, correct_top1, correct_top5 = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, targets in dataloader:\n",
    "            imgs, targets = imgs.to(device), targets.to(device)\n",
    "            outputs = model(imgs)\n",
    "            total += targets.size(0)\n",
    "            _, pred = outputs.topk(5, 1, True, True)\n",
    "            correct = pred.eq(targets.view(-1, 1).expand_as(pred))\n",
    "            correct_top1 += correct[:, :1].sum().item()\n",
    "            correct_top5 += correct[:, :5].sum().item()\n",
    "    acc1 = correct_top1 / total * 100\n",
    "    acc5 = correct_top5 / total * 100\n",
    "    return acc1, acc5\n",
    "\n",
    "# Evaluate all configurations\n",
    "print(\"acc_fp32 = evaluate_model(model_fp32, dataloader, device)\\n\")\n",
    "acc_fp32 = evaluate_model(model_fp32, dataloader, device)\n",
    "print(\"acc_bf15_lsb = evaluate_model(model_bf15_lsb, dataloader, device)\\n\")\n",
    "acc_bf15_lsb = evaluate_model(model_bf15_lsb, dataloader, device)\n",
    "print(\"acc_bf15_full = evaluate_model(model_bf15_full, dataloader, device)\\n\")\n",
    "acc_bf15_full = evaluate_model(model_bf15_full, dataloader, device)\n",
    "\n",
    "# Print results\n",
    "print(f\"FP32 Accuracy: Top-1 {acc_fp32[0]:.2f}%, Top-5 {acc_fp32[1]:.2f}%\")\n",
    "print(f\"BF15 (LSB Only) Accuracy: Top-1 {acc_bf15_lsb[0]:.2f}%, Top-5 {acc_bf15_lsb[1]:.2f}%\")\n",
    "print(f\"BF15 (LSB + Post-Alignment) Accuracy: Top-1 {acc_bf15_full[0]:.2f}%, Top-5 {acc_bf15_full[1]:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
