{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary Analysis\n",
    "> BF15 Numerical Accuracy\n",
    "\n",
    "> Date.11/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T00:09:12.811235Z",
     "iopub.status.busy": "2025-11-05T00:09:12.810671Z",
     "iopub.status.idle": "2025-11-05T00:09:12.823386Z",
     "shell.execute_reply": "2025-11-05T00:09:12.822368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n",
      "Python path: /usr/local/bin/python\n",
      "True\n",
      "NVIDIA A100-PCIE-40GB\n",
      "12.8\n"
     ]
    }
   ],
   "source": [
    "# Env info\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"Python path:\", sys.executable)\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T00:09:12.891692Z",
     "iopub.status.busy": "2025-11-05T00:09:12.891260Z",
     "iopub.status.idle": "2025-11-05T00:09:16.141994Z",
     "shell.execute_reply": "2025-11-05T00:09:16.141017Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "from torchvision import transforms\n",
    "from bf15_linear import replace_linear_with_bf15, bf15_left_matmul\n",
    "from bfspmat import replace_linear_with_bf15 as replace_linear_with_bf15_full\n",
    "from bfspmat import bf15_left_exp_int_matmul\n",
    "from vit import ImageNetValDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Error Budget Analysis\n",
    "- Max ULP (Units in the Last Place): The largest difference between the simulated BF15 and FP32 results.\n",
    "- Mean ULP: The average difference across all layers.\n",
    "- Histogram of ULPs: To visualize the distribution of errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T00:09:16.819571Z",
     "iopub.status.busy": "2025-11-05T00:09:16.819289Z",
     "iopub.status.idle": "2025-11-05T00:09:17.317448Z",
     "shell.execute_reply": "2025-11-05T00:09:17.316710Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max ULP (LSB Only): 0.359893798828125\n",
      "Mean ULP (LSB Only): 0.05424826592206955\n",
      "Max ULP (LSB + Post-Alignment): 0.2800254821777344\n",
      "Mean ULP (LSB + Post-Alignment): 0.051701657474040985\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 1. Error Budget Analysis\n",
    "# ==========================================\n",
    "def compute_error_budget(A, B, tile_k=64):\n",
    "    \"\"\"\n",
    "    Compute the error budget for BF15 truncation and post-alignment.\n",
    "    \"\"\"\n",
    "    # FP32 reference\n",
    "    y_ref = torch.matmul(A.to(torch.float32), B.to(torch.float32))\n",
    "\n",
    "    # BF15 with LSB truncation only\n",
    "    y_bf15_lsb = bf15_left_matmul(A, B)\n",
    "\n",
    "    # BF15 with LSB truncation + post-alignment\n",
    "    y_bf15_full = bf15_left_exp_int_matmul(A, B, tile_k=tile_k)\n",
    "\n",
    "    # Compute ULP differences\n",
    "    ulp_lsb = (y_bf15_lsb - y_ref).abs()\n",
    "    ulp_full = (y_bf15_full - y_ref).abs()\n",
    "\n",
    "    return ulp_lsb, ulp_full, y_ref, y_bf15_lsb, y_bf15_full\n",
    "\n",
    "# Generate random input tensors\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "A = torch.randn(128, 256, dtype=torch.bfloat16, device=device)\n",
    "B = torch.randn(256, 128, dtype=torch.bfloat16, device=device)\n",
    "\n",
    "# Compute error budget\n",
    "ulp_lsb, ulp_full, y_ref, y_bf15_lsb, y_bf15_full = compute_error_budget(A, B)\n",
    "\n",
    "# Plot histogram of ULPs\n",
    "density = False # Normalize the histogram\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.hist(ulp_lsb.cpu().numpy().flatten(), bins=50, alpha=0.5, label=\"LSB Truncation Only\", density=density)\n",
    "plt.hist(ulp_full.cpu().numpy().flatten(), bins=50, alpha=0.5, label=\"LSB + Post-Alignment\", density=density)\n",
    "plt.xlabel(\"ULP Error\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.legend()\n",
    "plt.title(\"Error Budget: ULP Distribution\")\n",
    "plt.savefig(\"error_budget_ulps.svg\", format=\"svg\")\n",
    "plt.show()\n",
    "\n",
    "# Print max and mean ULPs\n",
    "print(f\"Max ULP (LSB Only): {ulp_lsb.max().item()}\")\n",
    "print(f\"Mean ULP (LSB Only): {ulp_lsb.mean().item()}\")\n",
    "print(f\"Max ULP (LSB + Post-Alignment): {ulp_full.max().item()}\")\n",
    "print(f\"Mean ULP (LSB + Post-Alignment): {ulp_full.mean().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Ablation Study\n",
    "- Compare the outputs of the following configurations:\\\n",
    "FP32 baseline: Full precision.\\\n",
    "BF15 with LSB truncation only: Using `bf15_linear.py`.\\\n",
    "BF15 with LSB truncation + post-alignment: Using `bfspmat.py`.\n",
    "- Measure the accuracy (Top-1, Top-5) and inference time for each configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`wget https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz`\n",
    "\n",
    "`tar -xvzf imagenette2-320.tgz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T00:09:17.321508Z",
     "iopub.status.busy": "2025-11-05T00:09:17.321038Z",
     "iopub.status.idle": "2025-11-05T00:09:17.325889Z",
     "shell.execute_reply": "2025-11-05T00:09:17.325223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_fp32 = evaluate_model(model_fp32, dataloader, device)\n",
      "\n",
      "FP32 Accuracy: Top-1 16.00%, Top-5 16.00%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "acc_bf15_lsb = evaluate_model(model_bf15_lsb, dataloader, device)\n",
      "\n",
      "BF15 (LSB Only) Accuracy: Top-1 16.00%, Top-5 16.00%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "acc_bf15_full = evaluate_model(model_bf15_full, dataloader, device)\n",
      "\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 6.93 GiB. GPU 0 has a total capacity of 39.49 GiB of which 1.37 GiB is free. Process 1965571 has 38.12 GiB memory in use. Of the allocated memory 37.51 GiB is allocated by PyTorch, and 120.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 102\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m100\u001b[39m)\n\u001b[32m    101\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33macc_bf15_full = evaluate_model(model_bf15_full, dataloader, device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m acc_bf15_full = \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_bf15_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBF15 (LSB + Post-Alignment) Accuracy: Top-1 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_bf15_full[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%, Top-5 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_bf15_full[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    104\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m100\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 77\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(model, dataloader, device, micro_batch_size)\u001b[39m\n\u001b[32m     75\u001b[39m imgs_micro = imgs[i:i+micro_batch_size]\n\u001b[32m     76\u001b[39m targets_micro = targets[i:i+micro_batch_size]\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs_micro\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m total += targets_micro.size(\u001b[32m0\u001b[39m)\n\u001b[32m     79\u001b[39m _, pred = outputs.topk(\u001b[32m5\u001b[39m, \u001b[32m1\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1755\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1755\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1766\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1761\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1762\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1764\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1765\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1766\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1768\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1769\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torchvision/models/vision_transformer.py:298\u001b[39m, in \u001b[36mVisionTransformer.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    295\u001b[39m batch_class_token = \u001b[38;5;28mself\u001b[39m.class_token.expand(n, -\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)\n\u001b[32m    296\u001b[39m x = torch.cat([batch_class_token, x], dim=\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[38;5;66;03m# Classifier \"token\" as used by standard language architectures\u001b[39;00m\n\u001b[32m    301\u001b[39m x = x[:, \u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1755\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1755\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1766\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1761\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1762\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1764\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1765\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1766\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1768\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1769\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torchvision/models/vision_transformer.py:157\u001b[39m, in \u001b[36mEncoder.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    155\u001b[39m torch._assert(\u001b[38;5;28minput\u001b[39m.dim() == \u001b[32m3\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected (batch_size, seq_length, hidden_dim) got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    156\u001b[39m \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28minput\u001b[39m + \u001b[38;5;28mself\u001b[39m.pos_embedding\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ln(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1755\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1755\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1766\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1761\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1762\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1764\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1765\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1766\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1768\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1769\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py:245\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1755\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1755\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1766\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1761\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1762\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1764\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1765\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1766\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1768\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1769\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torchvision/models/vision_transformer.py:118\u001b[39m, in \u001b[36mEncoderBlock.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    115\u001b[39m x = x + \u001b[38;5;28minput\u001b[39m\n\u001b[32m    117\u001b[39m y = \u001b[38;5;28mself\u001b[39m.ln_2(x)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m y = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x + y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1755\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1755\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1766\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1761\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1762\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1764\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1765\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1766\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1768\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1769\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py:245\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1755\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1755\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1766\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1761\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1762\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1764\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1765\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1766\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1768\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1769\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Essay-Hy-FPCIM/vit_q/bfspmat.py:159\u001b[39m, in \u001b[36mBF15IntLinear.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    157\u001b[39m x2d = x.reshape(-\u001b[32m1\u001b[39m, x.shape[-\u001b[32m1\u001b[39m])\n\u001b[32m    158\u001b[39m \u001b[38;5;66;03m#  BF15  matmul\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m y2d = \u001b[43mbf15_left_exp_int_matmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m.\u001b[49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    161\u001b[39m     y2d = (y2d.to(torch.float32) + \u001b[38;5;28mself\u001b[39m.bias.to(torch.float32)).to(torch.bfloat16)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Essay-Hy-FPCIM/vit_q/bfspmat.py:85\u001b[39m, in \u001b[36mbf15_left_exp_int_matmul\u001b[39m\u001b[34m(A, B, tile_k)\u001b[39m\n\u001b[32m     83\u001b[39m abs_prod    = prod.abs()\n\u001b[32m     84\u001b[39m aligned_mag = abs_prod >> shift                                    \u001b[38;5;66;03m# (T,M,t,N), int32\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m aligned     = torch.where(prod >= \u001b[32m0\u001b[39m, aligned_mag, \u001b[43m-\u001b[49m\u001b[43maligned_mag\u001b[49m)    \u001b[38;5;66;03m# (T,M,t,N), int32\u001b[39;00m\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# 5)  ktile_k tile  S_tileE_tile\u001b[39;00m\n\u001b[32m     88\u001b[39m S_tile = aligned.sum(dim=\u001b[32m2\u001b[39m, dtype=torch.int32)                     \u001b[38;5;66;03m# (T,M,N), int32\u001b[39;00m\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 6.93 GiB. GPU 0 has a total capacity of 39.49 GiB of which 1.37 GiB is free. Process 1965571 has 38.12 GiB memory in use. Of the allocated memory 37.51 GiB is allocated by PyTorch, and 120.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 2. Ablation Study\n",
    "# ==========================================\n",
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "from bf15_linear import replace_linear_with_bf15\n",
    "from bfspmat import replace_linear_with_bf15 as replace_linear_with_bf15_full\n",
    "from vit import ImageNetValDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# Load ViT model\n",
    "weights = ViT_B_16_Weights.IMAGENET1K_V1\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_fp32 = vit_b_16(weights=weights).eval().to(device)\n",
    "\n",
    "# Clone models for BF15 configurations\n",
    "model_bf15_lsb = vit_b_16(weights=weights).eval()\n",
    "model_bf15_full = vit_b_16(weights=weights).eval()\n",
    "\n",
    "# Replace Linear layers\n",
    "replace_linear_with_bf15(model_bf15_lsb)  # LSB truncation only\n",
    "model_bf15_lsb.to(device)  # Ensure the model is on the correct device\n",
    "\n",
    "replace_linear_with_bf15_full(model_bf15_full)  # LSB + post-alignment\n",
    "model_bf15_full.to(device)  # Ensure the model is on the correct device\n",
    "\n",
    "# Load ImageNet validation dataset\n",
    "imagenet_root = \"./imagenette2-320/val\"  # Path to the validation dataset\n",
    "\n",
    "# Generate wnid_map directly from the folder structure\n",
    "def generate_wnid_map(root_dir):\n",
    "    classes = sorted(os.listdir(root_dir))\n",
    "    wnid_map = {cls: idx for idx, cls in enumerate(classes)}\n",
    "    return wnid_map\n",
    "\n",
    "wnid_map = generate_wnid_map(imagenet_root)\n",
    "\n",
    "# Preprocessing and dataset\n",
    "# Define preprocess\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),         # Convert images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet stats\n",
    "])\n",
    "\n",
    "subset_size = 50  # Use only 50 samples for evaluation\n",
    "dataset = ImageNetValDataset(imagenet_root, wnid_map, preprocess)\n",
    "subset_indices = torch.randperm(len(dataset))[:subset_size]\n",
    "subset = torch.utils.data.Subset(dataset, subset_indices)\n",
    "dataloader = DataLoader(subset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "\n",
    "# Evaluate models\n",
    "# def evaluate_model(model, dataloader, device):\n",
    "#     total, correct_top1, correct_top5 = 0, 0, 0\n",
    "#     with torch.no_grad():\n",
    "#         for imgs, targets in dataloader:\n",
    "#             imgs, targets = imgs.to(device), targets.to(device)\n",
    "#             outputs = model(imgs)\n",
    "#             total += targets.size(0)\n",
    "#             _, pred = outputs.topk(5, 1, True, True)\n",
    "#             correct = pred.eq(targets.view(-1, 1).expand_as(pred))\n",
    "#             correct_top1 += correct[:, :1].sum().item()\n",
    "#             correct_top5 += correct[:, :5].sum().item()\n",
    "#     acc1 = correct_top1 / total * 100\n",
    "#     acc5 = correct_top5 / total * 100\n",
    "#     return acc1, acc5\n",
    "def evaluate_model(model, dataloader, device, micro_batch_size=4):\n",
    "    total, correct_top1, correct_top5 = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, targets in dataloader:\n",
    "            imgs, targets = imgs.to(device), targets.to(device)\n",
    "            batch_size = imgs.size(0)\n",
    "            for i in range(0, batch_size, micro_batch_size):\n",
    "                imgs_micro = imgs[i:i+micro_batch_size]\n",
    "                targets_micro = targets[i:i+micro_batch_size]\n",
    "                outputs = model(imgs_micro)\n",
    "                total += targets_micro.size(0)\n",
    "                _, pred = outputs.topk(5, 1, True, True)\n",
    "                correct = pred.eq(targets_micro.view(-1, 1).expand_as(pred))\n",
    "                correct_top1 += correct[:, :1].sum().item()\n",
    "                correct_top5 += correct[:, :5].sum().item()\n",
    "    acc1 = correct_top1 / total * 100\n",
    "    acc5 = correct_top5 / total * 100\n",
    "    return acc1, acc5\n",
    "\n",
    "\n",
    "# Evaluate all configurations\n",
    "print(\"acc_fp32 = evaluate_model(model_fp32, dataloader, device)\\n\")\n",
    "acc_fp32 = evaluate_model(model_fp32, dataloader, device)\n",
    "print(f\"FP32 Accuracy: Top-1 {acc_fp32[0]:.2f}%, Top-5 {acc_fp32[1]:.2f}%\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "\n",
    "print(\"acc_bf15_lsb = evaluate_model(model_bf15_lsb, dataloader, device)\\n\")\n",
    "acc_bf15_lsb = evaluate_model(model_bf15_lsb, dataloader, device)\n",
    "print(f\"BF15 (LSB Only) Accuracy: Top-1 {acc_bf15_lsb[0]:.2f}%, Top-5 {acc_bf15_lsb[1]:.2f}%\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "\n",
    "print(\"acc_bf15_full = evaluate_model(model_bf15_full, dataloader, device)\\n\")\n",
    "acc_bf15_full = evaluate_model(model_bf15_full, dataloader, device)\n",
    "print(f\"BF15 (LSB + Post-Alignment) Accuracy: Top-1 {acc_bf15_full[0]:.2f}%, Top-5 {acc_bf15_full[1]:.2f}%\")\n",
    "print(\"-\" * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
