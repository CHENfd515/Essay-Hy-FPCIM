{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary Analysis\n",
    "> BF15 Numerical Accuracy\n",
    "\n",
    "> Date.11/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T00:09:12.811235Z",
     "iopub.status.busy": "2025-11-05T00:09:12.810671Z",
     "iopub.status.idle": "2025-11-05T00:09:12.823386Z",
     "shell.execute_reply": "2025-11-05T00:09:12.822368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n",
      "Python path: /usr/local/bin/python\n",
      "True\n",
      "NVIDIA A100-PCIE-40GB\n",
      "12.8\n"
     ]
    }
   ],
   "source": [
    "# Env info\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"Python path:\", sys.executable)\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T00:09:12.891692Z",
     "iopub.status.busy": "2025-11-05T00:09:12.891260Z",
     "iopub.status.idle": "2025-11-05T00:09:16.141994Z",
     "shell.execute_reply": "2025-11-05T00:09:16.141017Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "from torchvision import transforms\n",
    "from bf15_linear import replace_linear_with_bf15, bf15_left_matmul\n",
    "from bfspmat import replace_linear_with_bf15 as replace_linear_with_bf15_full\n",
    "from bfspmat import bf15_left_exp_int_matmul\n",
    "from vit import ImageNetValDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Error Budget Analysis\n",
    "- Max ULP (Units in the Last Place): The largest difference between the simulated BF15 and FP32 results.\n",
    "- Mean ULP: The average difference across all layers.\n",
    "- Histogram of ULPs: To visualize the distribution of errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T00:09:16.819571Z",
     "iopub.status.busy": "2025-11-05T00:09:16.819289Z",
     "iopub.status.idle": "2025-11-05T00:09:17.317448Z",
     "shell.execute_reply": "2025-11-05T00:09:17.316710Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max ULP (LSB Only): 0.33325958251953125\n",
      "Mean ULP (LSB Only): 0.05468299612402916\n",
      "Max ULP (LSB + Post-Alignment): 0.2949981689453125\n",
      "Mean ULP (LSB + Post-Alignment): 0.05255648493766785\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 1. Error Budget Analysis\n",
    "# ==========================================\n",
    "def compute_error_budget(A, B, tile_k=64):\n",
    "    \"\"\"\n",
    "    Compute the error budget for BF15 truncation and post-alignment.\n",
    "    \"\"\"\n",
    "    # FP32 reference\n",
    "    y_ref = torch.matmul(A.to(torch.float32), B.to(torch.float32))\n",
    "\n",
    "    # BF15 with LSB truncation only\n",
    "    y_bf15_lsb = bf15_left_matmul(A, B)\n",
    "\n",
    "    # BF15 with LSB truncation + post-alignment\n",
    "    y_bf15_full = bf15_left_exp_int_matmul(A, B, tile_k=tile_k)\n",
    "\n",
    "    # Compute ULP differences\n",
    "    ulp_lsb = (y_bf15_lsb - y_ref).abs()\n",
    "    ulp_full = (y_bf15_full - y_ref).abs()\n",
    "\n",
    "    return ulp_lsb, ulp_full, y_ref, y_bf15_lsb, y_bf15_full\n",
    "\n",
    "# Generate random input tensors\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "A = torch.randn(128, 256, dtype=torch.bfloat16, device=device)\n",
    "B = torch.randn(256, 128, dtype=torch.bfloat16, device=device)\n",
    "\n",
    "# Compute error budget\n",
    "ulp_lsb, ulp_full, y_ref, y_bf15_lsb, y_bf15_full = compute_error_budget(A, B)\n",
    "\n",
    "# Plot histogram of ULPs\n",
    "density = False # Normalize the histogram\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.hist(ulp_lsb.cpu().numpy().flatten(), bins=50, alpha=0.5, label=\"LSB Truncation Only\", density=density)\n",
    "plt.hist(ulp_full.cpu().numpy().flatten(), bins=50, alpha=0.5, label=\"LSB + Post-Alignment\", density=density)\n",
    "plt.xlabel(\"ULP Error\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.legend()\n",
    "plt.title(\"Error Budget: ULP Distribution (Normalized)\")\n",
    "plt.savefig(\"error_budget_ulps_normalized.svg\", format=\"svg\")\n",
    "plt.show()\n",
    "\n",
    "# Print max and mean ULPs\n",
    "print(f\"Max ULP (LSB Only): {ulp_lsb.max().item()}\")\n",
    "print(f\"Mean ULP (LSB Only): {ulp_lsb.mean().item()}\")\n",
    "print(f\"Max ULP (LSB + Post-Alignment): {ulp_full.max().item()}\")\n",
    "print(f\"Mean ULP (LSB + Post-Alignment): {ulp_full.mean().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Ablation Study\n",
    "- Compare the outputs of the following configurations:\\\n",
    "FP32 baseline: Full precision.\\\n",
    "BF15 with LSB truncation only: Using `bf15_linear.py`.\\\n",
    "BF15 with LSB truncation + post-alignment: Using `bfspmat.py`.\n",
    "- Measure the accuracy (Top-1, Top-5) and inference time for each configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`wget https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz`\n",
    "\n",
    "`tar -xvzf imagenette2-320.tgz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T00:09:17.321508Z",
     "iopub.status.busy": "2025-11-05T00:09:17.321038Z",
     "iopub.status.idle": "2025-11-05T00:09:17.325889Z",
     "shell.execute_reply": "2025-11-05T00:09:17.325223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_fp32 = evaluate_model(model_fp32, dataloader, device)\n",
      "\n",
      "FP32 Accuracy: Top-1 8.00%, Top-5 8.00%\n",
      "acc_bf15_lsb = evaluate_model(model_bf15_lsb, dataloader, device)\n",
      "\n",
      "BF15 (LSB Only) Accuracy: Top-1 8.00%, Top-5 8.00%\n",
      "acc_bf15_full = evaluate_model(model_bf15_full, dataloader, device)\n",
      "\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 13.85 GiB. GPU 0 has a total capacity of 39.49 GiB of which 9.52 GiB is free. Process 1679258 has 29.97 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 183.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 81\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBF15 (LSB Only) Accuracy: Top-1 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_bf15_lsb[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%, Top-5 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_bf15_lsb[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     80\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33macc_bf15_full = evaluate_model(model_bf15_full, dataloader, device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m acc_bf15_full = \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_bf15_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBF15 (LSB + Post-Alignment) Accuracy: Top-1 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_bf15_full[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%, Top-5 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_bf15_full[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 59\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(model, dataloader, device)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m imgs, targets \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[32m     58\u001b[39m     imgs, targets = imgs.to(device), targets.to(device)\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m     total += targets.size(\u001b[32m0\u001b[39m)\n\u001b[32m     61\u001b[39m     _, pred = outputs.topk(\u001b[32m5\u001b[39m, \u001b[32m1\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1755\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1755\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1766\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1761\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1762\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1764\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1765\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1766\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1768\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1769\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torchvision/models/vision_transformer.py:298\u001b[39m, in \u001b[36mVisionTransformer.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    295\u001b[39m batch_class_token = \u001b[38;5;28mself\u001b[39m.class_token.expand(n, -\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)\n\u001b[32m    296\u001b[39m x = torch.cat([batch_class_token, x], dim=\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[38;5;66;03m# Classifier \"token\" as used by standard language architectures\u001b[39;00m\n\u001b[32m    301\u001b[39m x = x[:, \u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1755\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1755\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1766\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1761\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1762\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1764\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1765\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1766\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1768\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1769\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torchvision/models/vision_transformer.py:157\u001b[39m, in \u001b[36mEncoder.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    155\u001b[39m torch._assert(\u001b[38;5;28minput\u001b[39m.dim() == \u001b[32m3\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected (batch_size, seq_length, hidden_dim) got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    156\u001b[39m \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28minput\u001b[39m + \u001b[38;5;28mself\u001b[39m.pos_embedding\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ln(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1755\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1755\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1766\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1761\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1762\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1764\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1765\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1766\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1768\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1769\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py:245\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1755\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1755\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1766\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1761\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1762\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1764\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1765\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1766\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1768\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1769\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torchvision/models/vision_transformer.py:118\u001b[39m, in \u001b[36mEncoderBlock.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    115\u001b[39m x = x + \u001b[38;5;28minput\u001b[39m\n\u001b[32m    117\u001b[39m y = \u001b[38;5;28mself\u001b[39m.ln_2(x)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m y = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x + y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1755\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1755\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1766\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1761\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1762\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1764\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1765\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1766\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1768\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1769\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py:245\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1755\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1755\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1766\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1761\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1762\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1764\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1765\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1766\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1768\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1769\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Essay-Hy-FPCIM/vit_q/bfspmat.py:159\u001b[39m, in \u001b[36mBF15IntLinear.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    157\u001b[39m x2d = x.reshape(-\u001b[32m1\u001b[39m, x.shape[-\u001b[32m1\u001b[39m])\n\u001b[32m    158\u001b[39m \u001b[38;5;66;03m#  BF15  matmul\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m y2d = \u001b[43mbf15_left_exp_int_matmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m.\u001b[49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    161\u001b[39m     y2d = (y2d.to(torch.float32) + \u001b[38;5;28mself\u001b[39m.bias.to(torch.float32)).to(torch.bfloat16)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Essay-Hy-FPCIM/vit_q/bfspmat.py:79\u001b[39m, in \u001b[36mbf15_left_exp_int_matmul\u001b[39m\u001b[34m(A, B, tile_k)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# 4) E_ref_tile = max_k(e_sum)\u001b[39;00m\n\u001b[32m     78\u001b[39m E_ref = e_sum.max(dim=\u001b[32m2\u001b[39m, keepdim=\u001b[38;5;28;01mTrue\u001b[39;00m).values                      \u001b[38;5;66;03m# (T,M,1,N)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m shift = (\u001b[43mE_ref\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43me_sum\u001b[49m).clamp_min_(\u001b[32m0\u001b[39m)                              \u001b[38;5;66;03m# (T,M,t,N), int32\u001b[39;00m\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m#   trunc toward 0:   aligned = trunc(prod / 2**shift)\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m#     abs() \u001b[39;00m\n\u001b[32m     83\u001b[39m abs_prod    = prod.abs()\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 13.85 GiB. GPU 0 has a total capacity of 39.49 GiB of which 9.52 GiB is free. Process 1679258 has 29.97 GiB memory in use. Of the allocated memory 29.30 GiB is allocated by PyTorch, and 183.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 2. Ablation Study\n",
    "# ==========================================\n",
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "from bf15_linear import replace_linear_with_bf15\n",
    "from bfspmat import replace_linear_with_bf15 as replace_linear_with_bf15_full\n",
    "from vit import ImageNetValDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# Load ViT model\n",
    "weights = ViT_B_16_Weights.IMAGENET1K_V1\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_fp32 = vit_b_16(weights=weights).eval().to(device)\n",
    "\n",
    "# Clone models for BF15 configurations\n",
    "model_bf15_lsb = vit_b_16(weights=weights).eval()\n",
    "model_bf15_full = vit_b_16(weights=weights).eval()\n",
    "\n",
    "# Replace Linear layers\n",
    "replace_linear_with_bf15(model_bf15_lsb)  # LSB truncation only\n",
    "model_bf15_lsb.to(device)  # Ensure the model is on the correct device\n",
    "\n",
    "replace_linear_with_bf15_full(model_bf15_full)  # LSB + post-alignment\n",
    "model_bf15_full.to(device)  # Ensure the model is on the correct device\n",
    "\n",
    "# Load ImageNet validation dataset\n",
    "imagenet_root = \"./imagenette2-320/val\"  # Path to the validation dataset\n",
    "\n",
    "# Generate wnid_map directly from the folder structure\n",
    "def generate_wnid_map(root_dir):\n",
    "    classes = sorted(os.listdir(root_dir))\n",
    "    wnid_map = {cls: idx for idx, cls in enumerate(classes)}\n",
    "    return wnid_map\n",
    "\n",
    "wnid_map = generate_wnid_map(imagenet_root)\n",
    "\n",
    "# Preprocessing and dataset\n",
    "# Define preprocess\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),         # Convert images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet stats\n",
    "])\n",
    "\n",
    "subset_size = 100  # Use only 100 samples for evaluation\n",
    "dataset = ImageNetValDataset(imagenet_root, wnid_map, preprocess)\n",
    "subset_indices = torch.randperm(len(dataset))[:subset_size]\n",
    "subset = torch.utils.data.Subset(dataset, subset_indices)\n",
    "dataloader = DataLoader(subset, batch_size=8, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "\n",
    "# Evaluate models\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    total, correct_top1, correct_top5 = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, targets in dataloader:\n",
    "            imgs, targets = imgs.to(device), targets.to(device)\n",
    "            outputs = model(imgs)\n",
    "            total += targets.size(0)\n",
    "            _, pred = outputs.topk(5, 1, True, True)\n",
    "            correct = pred.eq(targets.view(-1, 1).expand_as(pred))\n",
    "            correct_top1 += correct[:, :1].sum().item()\n",
    "            correct_top5 += correct[:, :5].sum().item()\n",
    "    acc1 = correct_top1 / total * 100\n",
    "    acc5 = correct_top5 / total * 100\n",
    "    return acc1, acc5\n",
    "\n",
    "# Evaluate all configurations\n",
    "print(\"acc_fp32 = evaluate_model(model_fp32, dataloader, device)\\n\")\n",
    "acc_fp32 = evaluate_model(model_fp32, dataloader, device)\n",
    "print(f\"FP32 Accuracy: Top-1 {acc_fp32[0]:.2f}%, Top-5 {acc_fp32[1]:.2f}%\")\n",
    "\n",
    "\n",
    "print(\"acc_bf15_lsb = evaluate_model(model_bf15_lsb, dataloader, device)\\n\")\n",
    "acc_bf15_lsb = evaluate_model(model_bf15_lsb, dataloader, device)\n",
    "print(f\"BF15 (LSB Only) Accuracy: Top-1 {acc_bf15_lsb[0]:.2f}%, Top-5 {acc_bf15_lsb[1]:.2f}%\")\n",
    "\n",
    "\n",
    "print(\"acc_bf15_full = evaluate_model(model_bf15_full, dataloader, device)\\n\")\n",
    "acc_bf15_full = evaluate_model(model_bf15_full, dataloader, device)\n",
    "print(f\"BF15 (LSB + Post-Alignment) Accuracy: Top-1 {acc_bf15_full[0]:.2f}%, Top-5 {acc_bf15_full[1]:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
