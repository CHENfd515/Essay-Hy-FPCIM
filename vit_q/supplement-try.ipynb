{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary Analysis\n",
    "> BF15 Numerical Accuracy\n",
    "\n",
    "> Date.11/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T00:09:12.811235Z",
     "iopub.status.busy": "2025-11-05T00:09:12.810671Z",
     "iopub.status.idle": "2025-11-05T00:09:12.823386Z",
     "shell.execute_reply": "2025-11-05T00:09:12.822368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n",
      "Python path: /usr/local/bin/python\n",
      "True\n",
      "NVIDIA A100-PCIE-40GB\n",
      "12.8\n"
     ]
    }
   ],
   "source": [
    "# Env info\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"Python path:\", sys.executable)\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T00:09:12.891692Z",
     "iopub.status.busy": "2025-11-05T00:09:12.891260Z",
     "iopub.status.idle": "2025-11-05T00:09:16.141994Z",
     "shell.execute_reply": "2025-11-05T00:09:16.141017Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "from torchvision import transforms\n",
    "from bf15_linear import replace_linear_with_bf15, bf15_left_matmul\n",
    "from bfspmat import replace_linear_with_bf15 as replace_linear_with_bf15_full\n",
    "from bfspmat import bf15_left_exp_int_matmul\n",
    "from vit import ImageNetValDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Error Budget Analysis\n",
    "- Max ULP (Units in the Last Place): The largest difference between the simulated BF15 and FP32 results.\n",
    "- Mean ULP: The average difference across all layers.\n",
    "- Histogram of ULPs: To visualize the distribution of errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T00:09:16.819571Z",
     "iopub.status.busy": "2025-11-05T00:09:16.819289Z",
     "iopub.status.idle": "2025-11-05T00:09:17.317448Z",
     "shell.execute_reply": "2025-11-05T00:09:17.316710Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max ULP (LSB Only): 0.4920501708984375\n",
      "Mean ULP (LSB Only): 0.05464150011539459\n",
      "Max ULP (LSB + Post-Alignment): 0.30110931396484375\n",
      "Mean ULP (LSB + Post-Alignment): 0.05207479000091553\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 1. Error Budget Analysis\n",
    "# ==========================================\n",
    "def compute_error_budget(A, B, tile_k=64):\n",
    "    \"\"\"\n",
    "    Compute the error budget for BF15 truncation and post-alignment.\n",
    "    \"\"\"\n",
    "    # FP32 reference\n",
    "    y_ref = torch.matmul(A.to(torch.float32), B.to(torch.float32))\n",
    "\n",
    "    # BF15 with LSB truncation only\n",
    "    y_bf15_lsb = bf15_left_matmul(A, B)\n",
    "\n",
    "    # BF15 with LSB truncation + post-alignment\n",
    "    y_bf15_full = bf15_left_exp_int_matmul(A, B, tile_k=tile_k)\n",
    "\n",
    "    # Compute ULP differences\n",
    "    ulp_lsb = (y_bf15_lsb - y_ref).abs()\n",
    "    ulp_full = (y_bf15_full - y_ref).abs()\n",
    "\n",
    "    return ulp_lsb, ulp_full, y_ref, y_bf15_lsb, y_bf15_full\n",
    "\n",
    "# Generate random input tensors\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "A = torch.randn(128, 256, dtype=torch.bfloat16, device=device)\n",
    "B = torch.randn(256, 128, dtype=torch.bfloat16, device=device)\n",
    "\n",
    "# Compute error budget\n",
    "ulp_lsb, ulp_full, y_ref, y_bf15_lsb, y_bf15_full = compute_error_budget(A, B)\n",
    "\n",
    "# Plot histogram of ULPs\n",
    "density = False # Normalize the histogram\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.hist(ulp_lsb.cpu().numpy().flatten(), bins=50, alpha=0.5, label=\"LSB Truncation Only\", density=density)\n",
    "plt.hist(ulp_full.cpu().numpy().flatten(), bins=50, alpha=0.5, label=\"LSB + Post-Alignment\", density=density)\n",
    "plt.xlabel(\"ULP Error\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.legend()\n",
    "plt.title(\"Error Budget: ULP Distribution\")\n",
    "plt.savefig(\"error_budget_ulps.svg\", format=\"svg\")\n",
    "plt.show()\n",
    "\n",
    "# Print max and mean ULPs\n",
    "print(f\"Max ULP (LSB Only): {ulp_lsb.max().item()}\")\n",
    "print(f\"Mean ULP (LSB Only): {ulp_lsb.mean().item()}\")\n",
    "print(f\"Max ULP (LSB + Post-Alignment): {ulp_full.max().item()}\")\n",
    "print(f\"Mean ULP (LSB + Post-Alignment): {ulp_full.mean().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Ablation Study\n",
    "- Compare the outputs of the following configurations:\\\n",
    "FP32 baseline: Full precision.\\\n",
    "BF15 with LSB truncation only: Using `bf15_linear.py`.\\\n",
    "BF15 with LSB truncation + post-alignment: Using `bfspmat.py`.\n",
    "- Measure the accuracy (Top-1, Top-5) and inference time for each configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`wget https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz`\n",
    "\n",
    "`tar -xvzf imagenette2-320.tgz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T00:09:17.321508Z",
     "iopub.status.busy": "2025-11-05T00:09:17.321038Z",
     "iopub.status.idle": "2025-11-05T00:09:17.325889Z",
     "shell.execute_reply": "2025-11-05T00:09:17.325223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_fp32 = evaluate_model(model_fp32, dataloader, device)\n",
      "\n",
      "FP32 Accuracy: Top-1 10.00%, Top-5 10.00%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "acc_bf15_lsb = evaluate_model(model_bf15_lsb, dataloader, device)\n",
      "\n",
      "BF15 (LSB Only) Accuracy: Top-1 10.00%, Top-5 10.00%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "acc_bf15_full = evaluate_model(model_bf15_full, dataloader, device)\n",
      "\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 6.93 GiB. GPU 0 has a total capacity of 39.49 GiB of which 1.37 GiB is free. Process 1971976 has 38.12 GiB memory in use. Of the allocated memory 37.51 GiB is allocated by PyTorch, and 120.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 102\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m100\u001b[39m)\n\u001b[32m    101\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33macc_bf15_full = evaluate_model(model_bf15_full, dataloader, device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m acc_bf15_full = \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_bf15_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBF15 (LSB + Post-Alignment) Accuracy: Top-1 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_bf15_full[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%, Top-5 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_bf15_full[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    104\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m100\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 77\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(model, dataloader, device, micro_batch_size)\u001b[39m\n\u001b[32m     75\u001b[39m imgs_micro = imgs[i:i+micro_batch_size]\n\u001b[32m     76\u001b[39m targets_micro = targets[i:i+micro_batch_size]\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs_micro\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m total += targets_micro.size(\u001b[32m0\u001b[39m)\n\u001b[32m     79\u001b[39m _, pred = outputs.topk(\u001b[32m5\u001b[39m, \u001b[32m1\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1755\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1755\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1766\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1761\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1762\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1764\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1765\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1766\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1768\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1769\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torchvision/models/vision_transformer.py:298\u001b[39m, in \u001b[36mVisionTransformer.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    295\u001b[39m batch_class_token = \u001b[38;5;28mself\u001b[39m.class_token.expand(n, -\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)\n\u001b[32m    296\u001b[39m x = torch.cat([batch_class_token, x], dim=\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[38;5;66;03m# Classifier \"token\" as used by standard language architectures\u001b[39;00m\n\u001b[32m    301\u001b[39m x = x[:, \u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1755\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1755\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1766\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1761\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1762\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1764\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1765\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1766\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1768\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1769\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torchvision/models/vision_transformer.py:157\u001b[39m, in \u001b[36mEncoder.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    155\u001b[39m torch._assert(\u001b[38;5;28minput\u001b[39m.dim() == \u001b[32m3\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected (batch_size, seq_length, hidden_dim) got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    156\u001b[39m \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28minput\u001b[39m + \u001b[38;5;28mself\u001b[39m.pos_embedding\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ln(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1755\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1755\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1766\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1761\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1762\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1764\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1765\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1766\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1768\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1769\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py:245\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1755\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1755\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1766\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1761\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1762\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1764\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1765\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1766\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1768\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1769\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torchvision/models/vision_transformer.py:118\u001b[39m, in \u001b[36mEncoderBlock.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    115\u001b[39m x = x + \u001b[38;5;28minput\u001b[39m\n\u001b[32m    117\u001b[39m y = \u001b[38;5;28mself\u001b[39m.ln_2(x)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m y = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x + y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1755\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1755\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1766\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1761\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1762\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1764\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1765\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1766\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1768\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1769\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py:245\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1755\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1755\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1766\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1761\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1762\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1763\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1764\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1765\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1766\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1768\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1769\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Essay-Hy-FPCIM/vit_q/bfspmat.py:159\u001b[39m, in \u001b[36mBF15IntLinear.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    157\u001b[39m x2d = x.reshape(-\u001b[32m1\u001b[39m, x.shape[-\u001b[32m1\u001b[39m])\n\u001b[32m    158\u001b[39m \u001b[38;5;66;03m# simulation: matmul\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m y2d = \u001b[43mbf15_left_exp_int_matmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m.\u001b[49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    161\u001b[39m     y2d = (y2d.to(torch.float32) + \u001b[38;5;28mself\u001b[39m.bias.to(torch.float32)).to(torch.bfloat16)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Essay-Hy-FPCIM/vit_q/bfspmat.py:85\u001b[39m, in \u001b[36mbf15_left_exp_int_matmul\u001b[39m\u001b[34m(A, B, tile_k)\u001b[39m\n\u001b[32m     83\u001b[39m abs_prod    = prod.abs()\n\u001b[32m     84\u001b[39m aligned_mag = abs_prod >> shift                                    \u001b[38;5;66;03m# (T,M,t,N), int32\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m aligned     = torch.where(prod >= \u001b[32m0\u001b[39m, aligned_mag, \u001b[43m-\u001b[49m\u001b[43maligned_mag\u001b[49m)    \u001b[38;5;66;03m# (T,M,t,N), int32\u001b[39;00m\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# 5) sum each tile -> S_tileE_tile\u001b[39;00m\n\u001b[32m     88\u001b[39m S_tile = aligned.sum(dim=\u001b[32m2\u001b[39m, dtype=torch.int32)                     \u001b[38;5;66;03m# (T,M,N), int32\u001b[39;00m\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 6.93 GiB. GPU 0 has a total capacity of 39.49 GiB of which 1.37 GiB is free. Process 1971976 has 38.12 GiB memory in use. Of the allocated memory 37.51 GiB is allocated by PyTorch, and 120.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 2. Ablation Study\n",
    "# ==========================================\n",
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "from bf15_linear import replace_linear_with_bf15\n",
    "from bfspmat import replace_linear_with_bf15 as replace_linear_with_bf15_full\n",
    "from vit import ImageNetValDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# Load ViT model\n",
    "weights = ViT_B_16_Weights.IMAGENET1K_V1\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_fp32 = vit_b_16(weights=weights).eval().to(device)\n",
    "\n",
    "# Clone models for BF15 configurations\n",
    "model_bf15_lsb = vit_b_16(weights=weights).eval()\n",
    "model_bf15_full = vit_b_16(weights=weights).eval()\n",
    "\n",
    "# Replace Linear layers\n",
    "replace_linear_with_bf15(model_bf15_lsb)  # LSB truncation only\n",
    "model_bf15_lsb.to(device)  # Ensure the model is on the correct device\n",
    "\n",
    "replace_linear_with_bf15_full(model_bf15_full)  # LSB + post-alignment\n",
    "model_bf15_full.to(device)  # Ensure the model is on the correct device\n",
    "\n",
    "# Load ImageNet validation dataset\n",
    "imagenet_root = \"./imagenette2-320/val\"  # Path to the validation dataset\n",
    "\n",
    "# Generate wnid_map directly from the folder structure\n",
    "def generate_wnid_map(root_dir):\n",
    "    classes = sorted(os.listdir(root_dir))\n",
    "    wnid_map = {cls: idx for idx, cls in enumerate(classes)}\n",
    "    return wnid_map\n",
    "\n",
    "wnid_map = generate_wnid_map(imagenet_root)\n",
    "\n",
    "# Preprocessing and dataset\n",
    "# Define preprocess\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),         # Convert images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet stats\n",
    "])\n",
    "\n",
    "subset_size = 50  # Use only 50 samples for evaluation\n",
    "dataset = ImageNetValDataset(imagenet_root, wnid_map, preprocess)\n",
    "subset_indices = torch.randperm(len(dataset))[:subset_size]\n",
    "subset = torch.utils.data.Subset(dataset, subset_indices)\n",
    "dataloader = DataLoader(subset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "\n",
    "# Evaluate models\n",
    "# def evaluate_model(model, dataloader, device):\n",
    "#     total, correct_top1, correct_top5 = 0, 0, 0\n",
    "#     with torch.no_grad():\n",
    "#         for imgs, targets in dataloader:\n",
    "#             imgs, targets = imgs.to(device), targets.to(device)\n",
    "#             outputs = model(imgs)\n",
    "#             total += targets.size(0)\n",
    "#             _, pred = outputs.topk(5, 1, True, True)\n",
    "#             correct = pred.eq(targets.view(-1, 1).expand_as(pred))\n",
    "#             correct_top1 += correct[:, :1].sum().item()\n",
    "#             correct_top5 += correct[:, :5].sum().item()\n",
    "#     acc1 = correct_top1 / total * 100\n",
    "#     acc5 = correct_top5 / total * 100\n",
    "#     return acc1, acc5\n",
    "def evaluate_model(model, dataloader, device, micro_batch_size=4):\n",
    "    total, correct_top1, correct_top5 = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, targets in dataloader:\n",
    "            imgs, targets = imgs.to(device), targets.to(device)\n",
    "            batch_size = imgs.size(0)\n",
    "            for i in range(0, batch_size, micro_batch_size):\n",
    "                imgs_micro = imgs[i:i+micro_batch_size]\n",
    "                targets_micro = targets[i:i+micro_batch_size]\n",
    "                outputs = model(imgs_micro)\n",
    "                total += targets_micro.size(0)\n",
    "                _, pred = outputs.topk(5, 1, True, True)\n",
    "                correct = pred.eq(targets_micro.view(-1, 1).expand_as(pred))\n",
    "                correct_top1 += correct[:, :1].sum().item()\n",
    "                correct_top5 += correct[:, :5].sum().item()\n",
    "    acc1 = correct_top1 / total * 100\n",
    "    acc5 = correct_top5 / total * 100\n",
    "    return acc1, acc5\n",
    "\n",
    "\n",
    "# Evaluate all configurations\n",
    "print(\"acc_fp32 = evaluate_model(model_fp32, dataloader, device)\\n\")\n",
    "acc_fp32 = evaluate_model(model_fp32, dataloader, device)\n",
    "print(f\"FP32 Accuracy: Top-1 {acc_fp32[0]:.2f}%, Top-5 {acc_fp32[1]:.2f}%\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "\n",
    "print(\"acc_bf15_lsb = evaluate_model(model_bf15_lsb, dataloader, device)\\n\")\n",
    "acc_bf15_lsb = evaluate_model(model_bf15_lsb, dataloader, device)\n",
    "print(f\"BF15 (LSB Only) Accuracy: Top-1 {acc_bf15_lsb[0]:.2f}%, Top-5 {acc_bf15_lsb[1]:.2f}%\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "\n",
    "print(\"acc_bf15_full = evaluate_model(model_bf15_full, dataloader, device)\\n\")\n",
    "acc_bf15_full = evaluate_model(model_bf15_full, dataloader, device)\n",
    "print(f\"BF15 (LSB + Post-Alignment) Accuracy: Top-1 {acc_bf15_full[0]:.2f}%, Top-5 {acc_bf15_full[1]:.2f}%\")\n",
    "print(\"-\" * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
